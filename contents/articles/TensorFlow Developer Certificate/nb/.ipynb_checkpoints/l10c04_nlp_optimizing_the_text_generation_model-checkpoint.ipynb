{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqm_LyEBWpb5"
   },
   "source": [
    "# Optimizing the Text Generation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9tOrTKeWrvc"
   },
   "source": [
    "You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence. By using more data and further tweaking the model, you'll be able to get improved results. We'll once again use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaJXt72UWuGr"
   },
   "source": [
    "## Import TensorFlow and related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLldsELxWnKy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Other imports for processing data\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbrrOYfjWyLV"
   },
   "source": [
    "## Get the Dataset\n",
    "\n",
    "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "J6N_FCQnWwag",
    "outputId": "238e67ee-fc7b-4f66-ab5a-f1bb610c2fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-09 03:56:43--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
      "Resolving drive.google.com (drive.google.com)... 172.217.212.100, 172.217.212.139, 172.217.212.113, ...\n",
      "Connecting to drive.google.com (drive.google.com)|172.217.212.100|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gquoughp2j9j9686dukdjcn69i8sp64b/1596945375000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2020-08-09 03:56:45--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gquoughp2j9j9686dukdjcn69i8sp64b/1596945375000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
      "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 173.194.198.132, 2607:f8b0:4001:c1c::84\n",
      "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|173.194.198.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘/tmp/songdata.csv’\n",
      "\n",
      "/tmp/songdata.csv       [   <=>              ]  69.08M   136MB/s    in 0.5s    \n",
      "\n",
      "2020-08-09 03:56:46 (136 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
    "    -O /tmp/songdata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SA_lgi2oW1Nb"
   },
   "source": [
    "## 250 Songs\n",
    "\n",
    "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
    "\n",
    "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMHBLtD9W3p0"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjRNvoA7WwqH"
   },
   "outputs": [],
   "source": [
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "  # Fit a Tokenizer on the corpus\n",
    "  if num_words > -1:\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "  else:\n",
    "    tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  return tokenizer\n",
    "\n",
    "def create_lyrics_corpus(dataset, field):\n",
    "  # Remove all other punctuation\n",
    "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
    "  # Make it lowercase\n",
    "  dataset[field] = dataset[field].str.lower()\n",
    "  # Make it one long string to split by line\n",
    "  lyrics = dataset[field].str.cat()\n",
    "  corpus = lyrics.split('\\n')\n",
    "  # Remove any trailing whitespace\n",
    "  for l in range(len(corpus)):\n",
    "    corpus[l] = corpus[l].rstrip()\n",
    "  # Remove any empty lines\n",
    "  corpus = [l for l in corpus if l != '']\n",
    "\n",
    "  return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u_aLcj15Wwwu",
    "outputId": "a79df7f1-991b-4566-fa7b-720319dbd6bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "def tokenize_corpus(corpus, num_words=-1):\n",
    "  # Fit a Tokenizer on the corpus\n",
    "  if num_words > -1:\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "  else:\n",
    "    tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(corpus)\n",
    "  return tokenizer\n",
    "\n",
    "# Read the dataset from csv - this time with 250 songs\n",
    "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
    "# Create the corpus using the 'text' column containing lyrics\n",
    "corpus = create_lyrics_corpus(dataset, 'text')\n",
    "# Tokenize the corpus\n",
    "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
    "total_words = tokenizer.num_words\n",
    "\n",
    "# There should be a lot more words now\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GknoUcaMW8OV"
   },
   "source": [
    "### Create Sequences and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDgU1IymWwii"
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tsequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences for equal input length \n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
    "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
    "# One-hot encode the labels\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9UvwA10W-3u"
   },
   "source": [
    "### Train a (Better) Text Generation Model\n",
    "\n",
    "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eikNiL6MW_fs",
    "outputId": "ea6bdfc8-a924-4c44-dd48-0784b88a575c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 5.9793 - accuracy: 0.0464\n",
      "Epoch 2/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 5.6729 - accuracy: 0.0517\n",
      "Epoch 3/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 5.4353 - accuracy: 0.0706\n",
      "Epoch 4/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 5.2396 - accuracy: 0.0959\n",
      "Epoch 5/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 5.0736 - accuracy: 0.1138\n",
      "Epoch 6/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 4.9118 - accuracy: 0.1312\n",
      "Epoch 7/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 4.7640 - accuracy: 0.1475\n",
      "Epoch 8/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 4.6310 - accuracy: 0.1603\n",
      "Epoch 9/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 4.5116 - accuracy: 0.1749\n",
      "Epoch 10/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 4.4031 - accuracy: 0.1877\n",
      "Epoch 11/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 4.3040 - accuracy: 0.1982\n",
      "Epoch 12/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 4.2072 - accuracy: 0.2111\n",
      "Epoch 13/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 4.1223 - accuracy: 0.2216\n",
      "Epoch 14/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 4.0432 - accuracy: 0.2312\n",
      "Epoch 15/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.9682 - accuracy: 0.2407\n",
      "Epoch 16/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.8968 - accuracy: 0.2493\n",
      "Epoch 17/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.8372 - accuracy: 0.2578\n",
      "Epoch 18/100\n",
      "1480/1480 [==============================] - 21s 15ms/step - loss: 3.7767 - accuracy: 0.2662\n",
      "Epoch 19/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.7177 - accuracy: 0.2765\n",
      "Epoch 20/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.6649 - accuracy: 0.2837\n",
      "Epoch 21/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.6100 - accuracy: 0.2915\n",
      "Epoch 22/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.5613 - accuracy: 0.3002\n",
      "Epoch 23/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.5162 - accuracy: 0.3058\n",
      "Epoch 24/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.4769 - accuracy: 0.3110\n",
      "Epoch 25/100\n",
      "1480/1480 [==============================] - 21s 15ms/step - loss: 3.4364 - accuracy: 0.3165\n",
      "Epoch 26/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.4019 - accuracy: 0.3218\n",
      "Epoch 27/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.3586 - accuracy: 0.3303\n",
      "Epoch 28/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.3278 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.2918 - accuracy: 0.3390\n",
      "Epoch 30/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.2596 - accuracy: 0.3451\n",
      "Epoch 31/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.2322 - accuracy: 0.3488\n",
      "Epoch 32/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.2007 - accuracy: 0.3525\n",
      "Epoch 33/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.1768 - accuracy: 0.3567\n",
      "Epoch 34/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 3.1389 - accuracy: 0.3624\n",
      "Epoch 35/100\n",
      "1480/1480 [==============================] - 21s 15ms/step - loss: 3.1257 - accuracy: 0.3661\n",
      "Epoch 36/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.0943 - accuracy: 0.3721\n",
      "Epoch 37/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.0838 - accuracy: 0.3738\n",
      "Epoch 38/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.0430 - accuracy: 0.3803\n",
      "Epoch 39/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.0197 - accuracy: 0.3824\n",
      "Epoch 40/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 3.0050 - accuracy: 0.3851\n",
      "Epoch 41/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.9751 - accuracy: 0.3904\n",
      "Epoch 42/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.9688 - accuracy: 0.3913\n",
      "Epoch 43/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.9346 - accuracy: 0.3962\n",
      "Epoch 44/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.9110 - accuracy: 0.4012\n",
      "Epoch 45/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.8977 - accuracy: 0.4013\n",
      "Epoch 46/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.8804 - accuracy: 0.4061\n",
      "Epoch 47/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.8633 - accuracy: 0.4073\n",
      "Epoch 48/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.8395 - accuracy: 0.4115\n",
      "Epoch 49/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.8264 - accuracy: 0.4139\n",
      "Epoch 50/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.8086 - accuracy: 0.4164\n",
      "Epoch 51/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.7955 - accuracy: 0.4198\n",
      "Epoch 52/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.7809 - accuracy: 0.4209\n",
      "Epoch 53/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.7686 - accuracy: 0.4242\n",
      "Epoch 54/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.7471 - accuracy: 0.4271\n",
      "Epoch 55/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.7294 - accuracy: 0.4304\n",
      "Epoch 56/100\n",
      "1480/1480 [==============================] - 21s 15ms/step - loss: 2.7173 - accuracy: 0.4324\n",
      "Epoch 57/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.7288 - accuracy: 0.4312\n",
      "Epoch 58/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6924 - accuracy: 0.4354\n",
      "Epoch 59/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.6754 - accuracy: 0.4402\n",
      "Epoch 60/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.6699 - accuracy: 0.4394\n",
      "Epoch 61/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6519 - accuracy: 0.4439\n",
      "Epoch 62/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.6439 - accuracy: 0.4441\n",
      "Epoch 63/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6315 - accuracy: 0.4471\n",
      "Epoch 64/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6133 - accuracy: 0.4494\n",
      "Epoch 65/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6082 - accuracy: 0.4509\n",
      "Epoch 66/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5930 - accuracy: 0.4528\n",
      "Epoch 67/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.5828 - accuracy: 0.4551\n",
      "Epoch 68/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5670 - accuracy: 0.4570\n",
      "Epoch 69/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.5577 - accuracy: 0.4601\n",
      "Epoch 70/100\n",
      "1480/1480 [==============================] - 21s 15ms/step - loss: 2.5416 - accuracy: 0.4622\n",
      "Epoch 71/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.5440 - accuracy: 0.4612\n",
      "Epoch 72/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5273 - accuracy: 0.4659\n",
      "Epoch 73/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5144 - accuracy: 0.4669\n",
      "Epoch 74/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.5159 - accuracy: 0.4656\n",
      "Epoch 75/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4965 - accuracy: 0.4703\n",
      "Epoch 76/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.4850 - accuracy: 0.4709\n",
      "Epoch 77/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.4727 - accuracy: 0.4739\n",
      "Epoch 78/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4649 - accuracy: 0.4758\n",
      "Epoch 79/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.4650 - accuracy: 0.4768\n",
      "Epoch 80/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4526 - accuracy: 0.4785\n",
      "Epoch 81/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.4348 - accuracy: 0.4837\n",
      "Epoch 82/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.4339 - accuracy: 0.4824\n",
      "Epoch 83/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.4273 - accuracy: 0.4844\n",
      "Epoch 84/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.4132 - accuracy: 0.4843\n",
      "Epoch 85/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.4075 - accuracy: 0.4868\n",
      "Epoch 86/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4022 - accuracy: 0.4869\n",
      "Epoch 87/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3978 - accuracy: 0.4886\n",
      "Epoch 88/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.3852 - accuracy: 0.4898\n",
      "Epoch 89/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3725 - accuracy: 0.4926\n",
      "Epoch 90/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.3912 - accuracy: 0.4896\n",
      "Epoch 91/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.3636 - accuracy: 0.4940\n",
      "Epoch 92/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3585 - accuracy: 0.4949\n",
      "Epoch 93/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.3484 - accuracy: 0.4956\n",
      "Epoch 94/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3390 - accuracy: 0.4998\n",
      "Epoch 95/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.3371 - accuracy: 0.4991\n",
      "Epoch 96/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3559 - accuracy: 0.4952\n",
      "Epoch 97/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.3367 - accuracy: 0.5007\n",
      "Epoch 98/100\n",
      "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3213 - accuracy: 0.5016\n",
      "Epoch 99/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.3096 - accuracy: 0.5057\n",
      "Epoch 100/100\n",
      "1480/1480 [==============================] - 22s 15ms/step - loss: 2.2980 - accuracy: 0.5071\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RqSb0Z2XDHm"
   },
   "source": [
    "### View the Training Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "w0MmOIdQW_oD",
    "outputId": "d93338a6-e50e-453b-e0cf-80aa44a51e23"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()\n",
    "\n",
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJLk4i6zXFgh"
   },
   "source": [
    "### Generate better lyrics!\n",
    "\n",
    "This time around, we should be able to get a more interesting output with less repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vf6bqyeyW_wv",
    "outputId": "70d73b24-9835-4314-d1a5-ba3dfc25b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills me one other time you are here is my life in of love life whole day colour sun kids heavens how turned pride man never bye never never said no way you for me through me and all our last night we used to nancy pleading for you to prays misfortune friends joy man fantasy life heavens pensabamos decision youre reason to dont be alright if you is happy baby ill see of you to cry bright goodnight the old little only way you and me and now i bound you baby that you make me smile and the knees\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETlytlBnXI-v"
   },
   "source": [
    "### Varying the Possible Outputs\n",
    "\n",
    "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
    "\n",
    "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hGI3dz0YW_tX",
    "outputId": "c1fda1f0-441a-4a16-eeec-2b43f82c50e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# Test the method with just the first word after the seed text\n",
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "predicted_probs = model.predict(token_list)[0]\n",
    "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
    "                             p=predicted_probs)\n",
    "# Running this cell multiple times should get you some variance in output\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "PUGX6kVAW_lk",
    "outputId": "76f0f347-f8be-45c9-f4a6-19910c6341a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im feeling chills a only way i will calls returning no tan for sun twice in star sight queen trapped quarter seems means distant fucks police losin will fuse runs heal rockin queen headline for citys dumb dumb ground janies mornin diamond twilight babys girlya las burden spiderman pirouette sit wholl give low joy shut sincere takes means distant softly downtown in midnight distant quarter prison roseyeah found age toys life thats headin the says of you loves a that can sometimes that ive not no reason for me than first angels i been givin two way true two is hand life block\n"
     ]
    }
   ],
   "source": [
    "# Use this process for the full output generation\n",
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "  predicted_probs = model.predict(token_list)[0]\n",
    "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
    "                               p=predicted_probs)\n",
    "  output_word = \"\"\n",
    "  for word, index in tokenizer.word_index.items():\n",
    "    if index == predicted:\n",
    "      output_word = word\n",
    "      break\n",
    "  seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "l10c04_nlp_optimizing_the_text_generation_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
