{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scikit-LLM\n",
        "- https://github.com/iryna-kondr/scikit-llm"
      ],
      "metadata": {
        "id": "2bGSdI5W5OCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ],
      "metadata": {
        "id": "XMFNCrPx5HwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hPZq1QcNcFP4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install scikit-llm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://platform.openai.com/account/api-keys\n",
        "- https://platform.openai.com/account/org-settings"
      ],
      "metadata": {
        "id": "oT_TMKX0dlMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm.config import SKLLMConfig\n",
        "\n",
        "SKLLMConfig.set_openai_key(\"<API_KEY>\")\n",
        "SKLLMConfig.set_openai_org(\"<ORGANIZATION_ID>\")"
      ],
      "metadata": {
        "id": "tWRMwTV0c_Mi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero Shot GPTClassifier\n",
        "- To perform text classification without being re-trained.\n",
        "- Scikit-LLM will automatically query the OpenAI API and transform the response into a regular list of labels.\n",
        "- A zero-shot classifier greatly depends on how the label itself is structured. It has to be expressed in natural language, be descriptive and self-explanatory."
      ],
      "metadata": {
        "id": "Zh-YAAh_e3tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm import ZeroShotGPTClassifier\n",
        "from skllm.datasets import get_classification_dataset\n",
        "\n",
        "# get classification dataset from sklearn\n",
        "X, y = get_classification_dataset()"
      ],
      "metadata": {
        "id": "rDKfiIkLefH-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(X[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPTDn3Rvf6tA",
        "outputId": "066ff43a-6142-4461-9d22-7515052436b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "The special effects in 'Star Battles: Nebula Conflict' were out of this world. I felt like I was actually in space. The storyline was incredibly engaging and left me wanting more. Excellent film.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y))\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfUCVPcafHL6",
        "outputId": "3b456cb5-38ab-4eb6-de55-2ba243e05927"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the model\n",
        "clf = ZeroShotGPTClassifier(openai_model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# fitting the data\n",
        "clf.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "f846faPsfAEC",
        "outputId": "0ab73ecd-6bab-4b45-9a1b-ec0824db90af"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ZeroShotGPTClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ZeroShotGPTClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ZeroShotGPTClassifier</label><div class=\"sk-toggleable__content\"><pre>ZeroShotGPTClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the data\n",
        "y_predict = clf.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0IZVmdKg3Fw",
        "outputId": "6eea108d-51bb-4e0b-a8f9-f8ad632c39b6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrLppMSwhFY-",
        "outputId": "dc6cd0a1-1716-4f1f-a8d4-e84b73a4aded"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "y_actual = y\n",
        "labels = list(set(y))\n",
        "print(labels)\n",
        "\n",
        "# Calculating Accuracy\n",
        "accuracy = accuracy_score(y_actual, y_predict)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Calculating Precision\n",
        "precision = precision_score(y_actual, y_predict, labels=labels, average='macro') # 'macro' calculates metrics for each label, and finds their unweighted mean.\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "\n",
        "# Calculating Recall\n",
        "recall = recall_score(y_actual, y_predict, labels=labels, average='macro')\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "# Calculating F1 Score\n",
        "f1 = f1_score(y_actual, y_predict, labels=labels, average='macro')\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculating Confusion Matrix\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "conf_matrix = confusion_matrix(y_actual, y_predict, labels=labels)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgsapO25o0Wp",
        "outputId": "7b86edb1-0404-403a-dde5-37e16fe7b027"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive', 'neutral', 'negative']\n",
            "Accuracy: 0.90\n",
            "Precision: 0.92\n",
            "Recall: 0.90\n",
            "F1 Score: 0.90\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  3  7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training without labeled data"
      ],
      "metadata": {
        "id": "XEEbbUp45TEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm import ZeroShotGPTClassifier\n",
        "from skllm.datasets import get_classification_dataset\n",
        "\n",
        "X, _ = get_classification_dataset()\n",
        "\n",
        "clf = ZeroShotGPTClassifier()\n",
        "clf.fit(None, [\"positive\", \"negative\", \"neutral\"])\n",
        "y_predict = clf.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls08MQ6X45Xu",
        "outputId": "e140fddd-2004-4cd5-fbf6-a95de8132bf1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:23<00:00,  1.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RltQPys7URi",
        "outputId": "72634fc6-9a11-49e4-d74e-69fbec633c43"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-Shot Text Classification\n",
        "- a few-shot classification, which means that the training samples will be added to prompt and passed to the model.\n",
        "- the training set should be small enough to fit into a single prompt (we recommend up to 10 samples per label);"
      ],
      "metadata": {
        "id": "GXkVaxKuFct7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm import FewShotGPTClassifier\n",
        "from skllm.datasets import get_classification_dataset\n",
        "\n",
        "X, y = get_classification_dataset()\n",
        "\n",
        "clf = FewShotGPTClassifier(openai_model=\"gpt-3.5-turbo\")\n",
        "clf.fit(X, y)\n",
        "y_predict = clf.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfL86vDTFpm8",
        "outputId": "fd6700e1-8ace-40aa-86f2-e70faeb4f69e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "y_actual = y\n",
        "labels = list(set(y))\n",
        "print(labels)\n",
        "\n",
        "# Calculating Accuracy\n",
        "accuracy = accuracy_score(y_actual, y_predict)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Calculating Precision\n",
        "precision = precision_score(y_actual, y_predict, labels=labels, average='macro')\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "\n",
        "# Calculating Recall\n",
        "recall = recall_score(y_actual, y_predict, labels=labels, average='macro')\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "# Calculating F1 Score\n",
        "f1 = f1_score(y_actual, y_predict, labels=labels, average='macro')\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculating Confusion Matrix\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "conf_matrix = confusion_matrix(y_actual, y_predict, labels=labels)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ-0q7IRFpjt",
        "outputId": "57543009-23cf-404a-fa95-fe4f10b6d018"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive', 'neutral', 'negative']\n",
            "Accuracy: 0.97\n",
            "Precision: 0.97\n",
            "Recall: 0.97\n",
            "F1 Score: 0.97\n",
            "\n",
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0 10  0]\n",
            " [ 0  1  9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic Few-Shot Text Classification\n",
        "- DynamicFewShotGPTClassifier dynamically selects N samples per class to include in the prompt. This allows the few-shot classifier to scale to datasets that are too large for the standard context window of LLMs.\n",
        "- During fitting, the whole dataset is partitioned by class, vectorized, and stored.\n",
        "- During inference, the annoy library is used for fast neighbor lookup, which allows including only the most similar examples in the prompt."
      ],
      "metadata": {
        "id": "IqjqSoocQj6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install scikit-llm[annoy]"
      ],
      "metadata": {
        "id": "cTEl-fOhQmyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm import DynamicFewShotGPTClassifier\n",
        "from skllm.datasets import get_classification_dataset\n",
        "\n",
        "X, y = get_classification_dataset()\n",
        "\n",
        "clf = DynamicFewShotGPTClassifier(n_examples=3)\n",
        "clf.fit(X, y)\n",
        "y_predict = clf.predict(X)"
      ],
      "metadata": {
        "id": "L3PFY04OQmvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Label Zero-Shot Text Classification"
      ],
      "metadata": {
        "id": "AMj4kENi7sE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing Multi-Label zeroshot module and classification dataset\n",
        "from skllm import MultiLabelZeroShotGPTClassifier\n",
        "from skllm.datasets import get_multilabel_classification_dataset\n",
        "\n",
        "# get classification dataset from sklearn\n",
        "X, y = get_multilabel_classification_dataset()"
      ],
      "metadata": {
        "id": "jrPySpxC7bCs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(X[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL_F5KNQ7_CQ",
        "outputId": "fc1e1128-9e0d-4c7f-fc8e-f9b9fef1ec8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "The delivery was super fast, but the product did not match the information provided on the website.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y))\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTHVwABU8EBF",
        "outputId": "2776057e-7ef6-4bd3-9d8f-0fe6d339ae58"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "[['Quality', 'Packaging'], ['Delivery', 'Product Information'], ['Product Variety', 'Customer Support'], ['Price', 'User Experience'], ['Delivery', 'Packaging'], ['Customer Support', 'Return Policy'], ['Product Information', 'Return Policy'], ['Service', 'Delivery', 'Quality'], ['Price', 'Quality', 'User Experience'], ['Product Information', 'Delivery']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the model\n",
        "clf = MultiLabelZeroShotGPTClassifier(max_labels=3)\n",
        "\n",
        "# fitting the model\n",
        "clf.fit(X, y)\n",
        "\n",
        "# making predictions\n",
        "y_predict = clf.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYkL3x5o76U-",
        "outputId": "6f45a01a-293a-4cb5-ad71-fbe63186359e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:07<00:00,  1.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I2NSG628NVU",
        "outputId": "974ff9f8-ddea-4e40-86c2-a996b7ccc704"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Quality', 'Packaging'], ['Delivery', 'Product Information'], ['Product Variety', 'Customer Support'], ['Price', 'User Experience'], ['Delivery', 'Packaging'], ['Customer Support', 'Return Policy'], ['Product Information', 'Return Policy'], ['Delivery', 'Quality'], ['Price', 'Quality', 'User Experience'], ['Product Information', 'Delivery']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
        "\n",
        "# Convert your lists into a binary matrix format using MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_bin = mlb.fit_transform(y)\n",
        "y_predict_bin = mlb.transform(y_predict)\n",
        "\n",
        "\n",
        "# Label-based metrics\n",
        "precision = precision_score(y_bin, y_predict_bin, average='micro')\n",
        "recall = recall_score(y_bin, y_predict_bin, average='micro')\n",
        "f1 = f1_score(y_bin, y_predict_bin, average='micro')\n",
        "\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1-Score: \", f1)\n",
        "\n",
        "# Exact Match Ratio\n",
        "exact_match_ratio = accuracy_score(y_bin, y_predict_bin)\n",
        "\n",
        "# Average Accuracy\n",
        "average_accuracy = (y_bin == y_predict_bin).mean()\n",
        "\n",
        "# Multi-label Confusion Matrix\n",
        "confusion_matrices = multilabel_confusion_matrix(y_bin, y_predict_bin)\n",
        "\n",
        "print(\"Exact Match Ratio: \", exact_match_ratio)\n",
        "print(\"Average Accuracy: \", average_accuracy)\n",
        "print(\"Confusion Matrices:\")\n",
        "for label_index, matrix in enumerate(confusion_matrices):\n",
        "    print(f\"Label: {mlb.classes_[label_index]}\")\n",
        "    print(matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loN5kD8k8WwV",
        "outputId": "6e1e71ca-742a-412d-cb7c-8ed091e66443"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision:  1.0\n",
            "Recall:  0.9545454545454546\n",
            "F1-Score:  0.9767441860465117\n",
            "Exact Match Ratio:  0.9\n",
            "Average Accuracy:  0.99\n",
            "Confusion Matrices:\n",
            "Label: Customer Support\n",
            "[[8 0]\n",
            " [0 2]]\n",
            "Label: Delivery\n",
            "[[6 0]\n",
            " [0 4]]\n",
            "Label: Packaging\n",
            "[[8 0]\n",
            " [0 2]]\n",
            "Label: Price\n",
            "[[8 0]\n",
            " [0 2]]\n",
            "Label: Product Information\n",
            "[[7 0]\n",
            " [0 3]]\n",
            "Label: Product Variety\n",
            "[[9 0]\n",
            " [0 1]]\n",
            "Label: Quality\n",
            "[[7 0]\n",
            " [0 3]]\n",
            "Label: Return Policy\n",
            "[[8 0]\n",
            " [0 2]]\n",
            "Label: Service\n",
            "[[9 0]\n",
            " [1 0]]\n",
            "Label: User Experience\n",
            "[[8 0]\n",
            " [0 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What if you don't have labelled data (Multi Labels case)?\n"
      ],
      "metadata": {
        "id": "aNTBrt7zAabB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting classification dataset for prediction only\n",
        "X, _ = get_multilabel_classification_dataset()\n",
        "\n",
        "# Defining all the labels that needs to predicted\n",
        "candidate_labels = [\n",
        "    \"Quality\",\n",
        "    \"Price\",\n",
        "    \"Delivery\",\n",
        "    \"Service\",\n",
        "    \"Product Variety\"\n",
        "]\n",
        "\n",
        "# creating the model\n",
        "clf = MultiLabelZeroShotGPTClassifier(max_labels=3)\n",
        "\n",
        "# fitting the labels only\n",
        "clf.fit(None, [candidate_labels])\n",
        "\n",
        "# predicting the data\n",
        "y_predict = clf.predict(X)\n",
        "print(y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szCL3qmP93YS",
        "outputId": "4322d525-5523-4a6e-be16-f42081587f02"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Quality'], ['Delivery'], ['Product Variety', 'Service'], ['Price', 'Service'], ['Delivery', 'Quality'], ['Service'], ['Quality', 'Service'], ['Service', 'Delivery', 'Quality'], ['Quality', 'Price'], ['Product Variety', 'Delivery']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Label Few-Shot Text Classification"
      ],
      "metadata": {
        "id": "qkNgER7OQDHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm.models.gpt.gpt_few_shot_clf import MultiLabelFewShotGPTClassifier\n",
        "from skllm.datasets import get_multilabel_classification_dataset\n",
        "\n",
        "X, y = get_multilabel_classification_dataset()\n",
        "\n",
        "clf = MultiLabelFewShotGPTClassifier(max_labels=2, openai_model=\"gpt-3.5-turbo\")\n",
        "clf.fit(X, y)\n",
        "labels = clf.predict(X)"
      ],
      "metadata": {
        "id": "Yp3LOQH5QFXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Vectorization and Classifier\n",
        "- Text vectorization is a process of converting text into numbers so that machines can understand and analyze it more easily."
      ],
      "metadata": {
        "id": "T8MJRIFuA8aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the GPTVectorizer class from the skllm.preprocessing module\n",
        "from skllm.preprocessing import GPTVectorizer\n",
        "from skllm.datasets import get_classification_dataset\n",
        "\n",
        "# get classification dataset from sklearn\n",
        "X, y = get_classification_dataset()\n",
        "\n",
        "# Creating an instance of the GPTVectorizer class and assigning it to the variable 'model'\n",
        "gpt_vectorizer = GPTVectorizer()\n",
        "\n",
        "# transorming the\n",
        "vectors = gpt_vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubJtDGscAmCr",
        "outputId": "a95cbf85-3bfc-457a-ee48-1ac81e78906e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:04<00:00,  6.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRwKTsR5BdgR",
        "outputId": "65a2b8a7-a4e4-4998-e2af-138dfa50243d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "I was absolutely blown away by the performances in 'Summer's End'. The acting was top-notch, and the plot had me gripped from start to finish. A truly captivating cinematic experience that I would highly recommend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vectors))\n",
        "print(len(vectors[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4FeZUoyBcVB",
        "outputId": "e888355e-8505-491f-fb2e-fedb06648dcc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Size of X_train:\", len(X_train))\n",
        "print(\"Size of X_test:\", len(X_test))\n",
        "print(\"Size of y_train:\", len(y_train))\n",
        "print(\"Size of y_test:\", len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwawfHLwDAtA",
        "outputId": "8d40a298-e7b1-480a-a876-a6feb542a526"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X_train: 24\n",
            "Size of X_test: 6\n",
            "Size of y_train: 24\n",
            "Size of y_test: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary modules and classes\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Creating an instance of LabelEncoder class\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Encoding the training labels 'y_train' using LabelEncoder\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "\n",
        "# Encoding the test labels 'y_test' using LabelEncoder\n",
        "y_test_encoded = le.transform(y_test)\n",
        "\n",
        "# Defining the steps of the pipeline as a list of tuples\n",
        "steps = [('GPT', GPTVectorizer()), ('Clf', XGBClassifier())]\n",
        "\n",
        "# Creating a pipeline with the defined steps\n",
        "clf = Pipeline(steps)\n",
        "\n",
        "# Fitting the pipeline on the training data 'X_train' and the encoded training labels 'y_train_encoded'\n",
        "clf.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predicting the labels for the test data 'X_test' using the trained pipeline\n",
        "y_predict = clf.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kqPpwr4BR04",
        "outputId": "2a36fdb2-7379-46fd-bf9b-9d4fae668eeb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24/24 [00:03<00:00,  6.40it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00,  7.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWR1DVo8EDlD",
        "outputId": "109371e4-17f9-4df5-8af4-cd7dd4fc4100"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "y_actual = y_test_encoded\n",
        "labels = list(set(y))\n",
        "print(labels)\n",
        "\n",
        "# Calculating Accuracy\n",
        "accuracy = accuracy_score(y_actual, y_predict)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Calculating Precision\n",
        "precision = precision_score(y_actual, y_predict, average='macro')\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "\n",
        "# Calculating Recall\n",
        "recall = recall_score(y_actual, y_predict, average='macro')\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "# Calculating F1 Score\n",
        "f1 = f1_score(y_actual, y_predict, average='macro')\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculating Confusion Matrix\n",
        "labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "conf_matrix = confusion_matrix(y_actual, y_predict)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3ijNuFUDonq",
        "outputId": "681e58a2-b72b-488d-ad69-e45355454054"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['positive', 'neutral', 'negative']\n",
            "Accuracy: 0.50\n",
            "Precision: 0.33\n",
            "Recall: 0.50\n",
            "F1 Score: 0.40\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 2 0]\n",
            " [0 1 1]\n",
            " [0 0 2]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Summarization\n",
        "- You can use it in two ways: on its own or as a step before doing something else (like reducing the size of the data.\n",
        "- max_words hyperparameter acts as a flexible limit for the number of words in the generated summaries. It is not strictly enforced beyond the provided prompt."
      ],
      "metadata": {
        "id": "mzDKOfn9RccF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the GPTSummarizer class from the skllm.preprocessing module\n",
        "from skllm.preprocessing import GPTSummarizer\n",
        "\n",
        "# Importing the get_summarization_dataset function\n",
        "from skllm.datasets import get_summarization_dataset\n",
        "\n",
        "# Calling the get_summarization_dataset function\n",
        "X = get_summarization_dataset()"
      ],
      "metadata": {
        "id": "EhPnzYxKD1KV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eqvvpTWRyZI",
        "outputId": "966f334a-ad91-4e0d-fbe3-e5116d7b4b3d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "The AI research company, OpenAI, has launched a new language model called GPT-4. This model is the latest in a series of transformer-based AI systems designed to perform complex tasks, such as generating human-like text, translating languages, and answering questions. According to OpenAI, GPT-4 is even more powerful and versatile than its predecessors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance of the GPTSummarizer\n",
        "s = GPTSummarizer(openai_model='gpt-3.5-turbo', max_words=15)\n",
        "\n",
        "# Applying the fit_transform method of the GPTSummarizer instance to the input data 'X'.\n",
        "# It fits the model to the data and generates the summaries, which are assigned to the variable 'summaries'\n",
        "summaries = s.fit_transform(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiZYXAZFRwjr",
        "outputId": "720ccc5a-9d72-4d88-8458-a030f53a172c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(summaries))\n",
        "summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWX27URBSMZ5",
        "outputId": "ea1d0d70-a5f2-4134-eb1c-c1de3c9c9aad"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['OpenAI has released GPT-4, a powerful and versatile language model for complex tasks.',\n",
              "       'John bought groceries in the morning and made a fruit salad for his guests in the evening.',\n",
              "       \"NASA's first Mars rover, Sojourner, launched in 1996, greatly contributed to our understanding of the Red Planet.\",\n",
              "       'Regular exercise improves memory and cognitive function in older adults, recommends 30 minutes daily.',\n",
              "       'The Eiffel Tower, completed in 1889, is a beloved symbol of Paris and French architecture.',\n",
              "       'Microsoft announces new version of Windows with improved security and redesigned user interface.',\n",
              "       'WHO declares global public health emergency due to unknown virus outbreak, urges nations to strengthen response systems.',\n",
              "       \"Paris, France will host the 2024 Olympics, marking the city's third time hosting the games.\",\n",
              "       \"Apple's latest iPhone model features improved camera, faster processor, longer battery life, launching soon.\",\n",
              "       'New bird species found in Amazon rainforest with unique bright plumage, exciting ornithologists globally.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Translation"
      ],
      "metadata": {
        "id": "pHIaAGWxSkH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skllm.preprocessing import GPTTranslator\n",
        "from skllm.datasets import get_translation_dataset\n",
        "\n",
        "X = get_translation_dataset()"
      ],
      "metadata": {
        "id": "DIsHW-N2SOgv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKbnNSmpSwtC",
        "outputId": "5f855b44-e051-4cb6-fd25-372e1c1ca992"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Me encanta bailar salsa y bachata. Es una forma divertida de expresarme.',\n",
              " \"J'ai passé mes dernières vacances en Grèce. Les plages étaient magnifiques.\",\n",
              " 'Ich habe gestern ein tolles Buch gelesen. Die Geschichte war fesselnd bis zum Ende.',\n",
              " 'Gosto de cozinhar pratos tradicionais italianos. O espaguete à carbonara é um dos meus favoritos.',\n",
              " 'Mám v plánu letos v létě vyrazit na výlet do Itálie. Doufám, že navštívím Řím a Benátky.',\n",
              " 'Mijn favoriete hobby is fotograferen. Ik hou ervan om mooie momenten vast te leggen.']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = GPTTranslator(openai_model=\"gpt-3.5-turbo\", output_language=\"English\")\n",
        "translated_text = t.fit_transform(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elfFFijQSuyg",
        "outputId": "de8d7e7c-3d2f-48eb-fe54-d5f7c33a6957"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:05<00:00,  1.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZS1hz4cS3Mn",
        "outputId": "85ae47b9-b91a-4a3b-cc9b-3d73201e93f0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"I love to dance salsa and bachata. It's a fun way to express myself.\",\n",
              "       'I spent my last vacation in Greece. The beaches were beautiful.',\n",
              "       'I read a great book yesterday. The story was captivating until the end.',\n",
              "       'I enjoy cooking traditional Italian dishes. Spaghetti carbonara is one of my favorites.',\n",
              "       'I plan to go on a trip to Italy this summer. I hope to visit Rome and Venice.',\n",
              "       'My favorite hobby is photography. I love capturing beautiful moments.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "loh4magYS66x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}